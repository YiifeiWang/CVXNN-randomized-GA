{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51260e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_utils import movingaverage\n",
    "from main_FT_input_num import load_data_and_embeddings\n",
    "import torch\n",
    "from utils import accuracy\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86275cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'cifar10'\n",
    "embed = 'OpenAI'\n",
    "plot_linear = True\n",
    "cvxpy = False\n",
    "if data_name == 'ECG-signal':\n",
    "    cvxpy = True\n",
    "sdim = 100\n",
    "train_num_str = '_TN_f1'\n",
    "plot_full = False\n",
    "eps = True\n",
    "Hidden = 50\n",
    "shuffle = True\n",
    "skip = False\n",
    "Hidden_str = '_Hidden{}'.format(Hidden)\n",
    "Hidden_str_lasso = '_Hidden500'\n",
    "if data_name=='cola' and Hidden == 10:\n",
    "    Hidden_str = ''\n",
    "shuffle_str = ''\n",
    "if shuffle == True:\n",
    "    shuffle_str = '_shuffle'\n",
    "skip_str = ''\n",
    "if skip == True:\n",
    "    skip_str = '_skip'\n",
    "solver_str = ''\n",
    "if cvxpy == True:\n",
    "    solver_str = '_cvxpy'\n",
    "eps_str = ''\n",
    "if eps == True:\n",
    "    eps_str = '_eps1e-08'\n",
    "sdim_str = ''\n",
    "if sdim!=100:\n",
    "    sdim_str = '_sdim{}'.format(sdim)\n",
    "seed = 1\n",
    "aug_str = '_aug'\n",
    "str_bundle = sdim_str+shuffle_str+skip_str+solver_str+eps_str\n",
    "container = np.load('results/FT_{}_T_f1{}_{}_cvx{}{}_NT5_seed{}.npz'.format(data_name,train_num_str,embed,Hidden_str,str_bundle,seed),allow_pickle=True)\n",
    "result_dict_cvx = container['result_dict'].item()\n",
    "sdim_str_alt = ''#'_sdim-1'\n",
    "str_bundle = sdim_str_alt+shuffle_str+skip_str\n",
    "container = np.load('results/FT_{}_T_f1{}_{}_noncvx{}{}_NT5_seed{}.npz'.format(data_name,train_num_str,embed,Hidden_str,str_bundle,seed),allow_pickle=True)\n",
    "result_dict_noncvx = container['result_dict'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf4726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "if 'ECG' in data_name:\n",
    "    data_path = './data/ECG/'\n",
    "\n",
    "if data_name == 'IMDB':\n",
    "    Bert_embeddings, Bert_labels = load_data_and_embeddings(\"IMDB-Bert-full\", data_path=data_path)\n",
    "    OpenAI_embeddings, OpenAI_labels = load_data_and_embeddings(\"IMDB-OpenAI-full\", data_path=data_path)\n",
    "elif data_name == 'Amazon':\n",
    "    Bert_embeddings, Bert_labels = load_data_and_embeddings(\"Amazon-Bert-30K\", data_path=data_path)\n",
    "    OpenAI_embeddings, OpenAI_labels = load_data_and_embeddings(\"Amazon-OpenAI-30K\", data_path=data_path)\n",
    "elif data_name == 'cvx-forum':\n",
    "    Bert_embeddings, Bert_labels = load_data_and_embeddings(\"cvx-forum-Bert-full\", data_path=data_path)\n",
    "    OpenAI_embeddings, OpenAI_labels = load_data_and_embeddings(\"cvx-forum-OpenAI-full\", data_path=data_path)\n",
    "elif data_name == 'cola':\n",
    "    Bert_embeddings, Bert_labels = load_data_and_embeddings(\"glue-cola-Bert-full\", data_path=data_path)\n",
    "    OpenAI_embeddings, OpenAI_labels = load_data_and_embeddings(\"glue-cola-OpenAI-full\", data_path=data_path)\n",
    "elif data_name == 'qqp':\n",
    "    Bert_embeddings, Bert_labels = load_data_and_embeddings(\"glue-qqp-Bert-50K\", data_path=data_path)\n",
    "    OpenAI_embeddings, OpenAI_labels = load_data_and_embeddings(\"glue-qqp-OpenAI-50K\", data_path=data_path)\n",
    "elif data_name == 'ECG-signal':\n",
    "    _, labels = load_data_and_embeddings(\"ECG-report\", data_path=data_path)\n",
    "    embeddings, _ = load_data_and_embeddings(\"ECG-signal\", data_path=data_path)\n",
    "    embeddings = torch.clamp(embeddings,max=1)*0.15\n",
    "    Bert_embeddings, Bert_labels = embeddings.clone(), labels.copy()\n",
    "    OpenAI_embeddings, OpenAI_labels = embeddings.clone(), labels.copy()\n",
    "elif data_name == 'ECG-report':\n",
    "    embeddings, labels = load_data_and_embeddings(\"ECG-report\", data_path=data_path)\n",
    "    embeddings = torch.nan_to_num(embeddings)\n",
    "    Bert_embeddings, Bert_labels = embeddings.clone(), labels.copy()\n",
    "    OpenAI_embeddings, OpenAI_labels = embeddings.clone(), labels.copy()\n",
    "elif data_name == 'ECG-sr':\n",
    "    embeddings_signal, _ = load_data_and_embeddings(\"ECG-signal\", data_path=data_path)\n",
    "    embeddings_report, labels = load_data_and_embeddings(\"ECG-report\", data_path=data_path)\n",
    "    embeddings_signal = torch.clamp(embeddings_signal,max=1)*0.15\n",
    "    embeddings_report = torch.nan_to_num(embeddings_report)\n",
    "    embeddings = torch.cat([embeddings_signal,embeddings_report],dim=1)\n",
    "    Bert_embeddings, Bert_labels = embeddings.clone(), labels.copy()\n",
    "    OpenAI_embeddings, OpenAI_labels = embeddings.clone(), labels.copy()\n",
    "elif data_name == 'mnist':\n",
    "    container = np.load('{}mnist_transformed.npz'.format(data_path))\n",
    "    training_data_np = container['train_data'].reshape([60000,-1])\n",
    "    training_labels_np = container['train_label']\n",
    "    test_data_np = container['test_data'].reshape([10000,-1])\n",
    "    test_labels_np = container['test_label']\n",
    "    embeddings = np.concatenate([training_data_np, test_data_np],axis=0)\n",
    "    labels = np.concatenate([training_labels_np, test_labels_np])\n",
    "    index1 = np.where(labels==0)\n",
    "    index2 = np.where(labels==1)\n",
    "    index = np.concatenate([index1[0],index2[0]])\n",
    "    embeddings = embeddings[index,:]\n",
    "    labels = labels[index]\n",
    "    embeddings = torch.tensor(embeddings).float()\n",
    "    Bert_embeddings, Bert_labels = embeddings.clone(), labels.copy()\n",
    "    OpenAI_embeddings, OpenAI_labels = embeddings.clone(), labels.copy()\n",
    "elif data_name == 'cifar10':\n",
    "    container = np.load('{}cifar10_transformed.npz'.format(data_path))\n",
    "    training_data_np = container['train_data'].reshape([50000,-1])\n",
    "    training_labels_np = container['train_label']\n",
    "    test_data_np = container['test_data'].reshape([10000,-1])\n",
    "    test_labels_np = container['test_label']\n",
    "    embeddings = np.concatenate([training_data_np, test_data_np],axis=0)\n",
    "    labels = np.concatenate([training_labels_np, test_labels_np])\n",
    "    index1 = np.where(labels==0)\n",
    "    index2 = np.where(labels==1)\n",
    "    index = np.concatenate([index1[0],index2[0]])\n",
    "    embeddings = embeddings[index,:]\n",
    "    labels = labels[index]\n",
    "    embeddings = torch.tensor(embeddings).float()\n",
    "    Bert_embeddings, Bert_labels = embeddings.clone(), labels.copy()\n",
    "    OpenAI_embeddings, OpenAI_labels = embeddings.clone(), labels.copy()\n",
    "elif data_name == 'ECG-signal-mfcc':\n",
    "    _, labels = load_data_and_embeddings(\"ECG-report\", data_path=data_path)\n",
    "    embeddings = np.load('{}signal_mfcc.npy'.format(data_path))\n",
    "    embeddings = torch.tensor(embeddings).float()\n",
    "    Bert_embeddings, Bert_labels = embeddings.clone(), labels.copy()\n",
    "    OpenAI_embeddings, OpenAI_labels = embeddings.clone(), labels.copy()\n",
    "elif data_name == 'ECG-sr-mfcc':\n",
    "    embeddings = np.load('{}signal_mfcc.npy'.format(data_path))\n",
    "    embeddings_signal = torch.tensor(embeddings).float()\n",
    "    embeddings_report, labels = load_data_and_embeddings(\"ECG-report\", data_path=data_path)\n",
    "    embeddings_report = torch.nan_to_num(embeddings_report)\n",
    "    embeddings = torch.cat([embeddings_signal,embeddings_report],dim=1)\n",
    "    Bert_embeddings, Bert_labels = embeddings.clone(), labels.copy()\n",
    "    OpenAI_embeddings, OpenAI_labels = embeddings.clone(), labels.copy()\n",
    "\n",
    "if plot_linear:\n",
    "    n = Bert_embeddings.shape[0]\n",
    "    num_train = n//2\n",
    "\n",
    "    index = np.arange(n)\n",
    "    np.random.seed(2)\n",
    "    np.random.shuffle(index)\n",
    "    Bert_train = Bert_embeddings[index[:num_train]].detach().numpy()\n",
    "    label_train = Bert_labels[index[:num_train]]\n",
    "    OpenAI_train = OpenAI_embeddings[index[:num_train]].detach().numpy()\n",
    "\n",
    "    Bert_test = Bert_embeddings[index[num_train:n]].detach().numpy()\n",
    "    label_test = Bert_labels[index[num_train:n]]\n",
    "    OpenAI_test = OpenAI_embeddings[index[num_train:n]].detach().numpy()\n",
    "\n",
    "    label_train = np.array(label_train)*2-1\n",
    "    label_test = np.array(label_test)*2-1\n",
    "\n",
    "    training_data_np = Bert_train.copy()\n",
    "    training_labels_np = label_train.copy()\n",
    "    test_data_np = Bert_test.copy()\n",
    "    test_labels_np = label_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d81bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['Gaussian', 'Geometric_Algebra']\n",
    "num_trial = 5\n",
    "beta_list = [1e-3,1e-4,1e-5,1e-6]\n",
    "lr_list = [1e-2,1e-3,1e-4]\n",
    "\n",
    "def compute_test_acc_cvx(result_dict_cvx,input_num_list,mode='early_stop', patience=5, threshold=1e-2,coef=1):\n",
    "    time_array = np.zeros([num_trial, 2,len(beta_list)])\n",
    "    test_acc_array = np.zeros([len(input_num_list),2,len(beta_list),num_trial])\n",
    "    t_array = np.zeros([len(input_num_list)])\n",
    "    for i0, input_num in enumerate(input_num_list):\n",
    "        for i in range(num_trial):\n",
    "            for j1, method in enumerate(methods):\n",
    "                for j2, beta in enumerate(beta_list):\n",
    "                    key = '{}_{}_{}_{}'.format(input_num,method,beta,i)\n",
    "                    metrics = result_dict_cvx[key]\n",
    "                    time_array[i,j1,j2] =  metrics.time[-1]\n",
    "                    acc_array = np.array(metrics.test_accuracy)\n",
    "                    if mode=='early_stop':\n",
    "                        idx = early_stop(acc_array,patience=patience, threshold=threshold)\n",
    "                    elif mode=='best':\n",
    "                        idx = np.argmax(acc_array)\n",
    "                    time_array[i,j1,j2] = metrics.time[idx]\n",
    "                    \n",
    "        t0 = coef*np.min(time_array[:,:,:])\n",
    "\n",
    "        t_array[i0] = t0\n",
    "        print(t0)\n",
    "        for i in range(num_trial):\n",
    "            for j1, method in enumerate(methods):\n",
    "                for j2, beta in enumerate(beta_list):\n",
    "                    key = '{}_{}_{}_{}'.format(input_num,method,beta,i)\n",
    "                    metrics = result_dict_cvx[key]\n",
    "                    try:\n",
    "                        idx = np.where(metrics.time>=t0)[0][0]\n",
    "                    except:\n",
    "                        idx = -1\n",
    "                    test_acc_array[i0,j1,j2,i] = metrics.test_accuracy[idx]\n",
    "        \n",
    "    return test_acc_array, t_array\n",
    "\n",
    "def compute_test_acc_noncvx(result_dict_noncvx,t_array,input_num_list):\n",
    "    time_array = np.zeros([num_trial, 2,len(beta_list)])\n",
    "    test_acc_array_noncvx = np.zeros([len(input_num_list),len(lr_list),num_trial])\n",
    "    for i0, input_num in enumerate(input_num_list):\n",
    "        t0 = t_array[i0]\n",
    "        for i in range(num_trial):\n",
    "            for j1, lr in enumerate(lr_list):\n",
    "                key = '{}_{}_{}'.format(input_num,lr,i)\n",
    "                metrics = result_dict_noncvx[key]\n",
    "                try:\n",
    "                    idx = np.where(metrics['cum_time']>=t0)[0][0]+1\n",
    "                except:\n",
    "                    idx = -1\n",
    "#                 idx = -1\n",
    "                test_acc_array_noncvx[i0,j1,i] = metrics['test_acc'][idx]\n",
    "    return test_acc_array_noncvx\n",
    "\n",
    "def compute_test_acc_lasso(result_dict_lasso,input_num_list,beta_list):\n",
    "    test_acc_array_lasso = np.zeros([len(input_num_list),len(beta_list),num_trial])\n",
    "    for i0, input_num in enumerate(input_num_list):\n",
    "        for i in range(num_trial):\n",
    "            for j, beta in enumerate(beta_list):\n",
    "                key = '{}_{}_{}'.format(input_num,beta,i)\n",
    "                metrics = result_dict_lasso[key]\n",
    "                test_acc_array_lasso[i0,j,i] =  metrics['test_acc']\n",
    "\n",
    "    return test_acc_array_lasso\n",
    "\n",
    "def early_stop(test_acc, patience=5, threshold=1e-2):\n",
    "    n = len(test_acc)\n",
    "    if n<patience:\n",
    "        return n-1\n",
    "    i = patience\n",
    "    loss = 1-test_acc\n",
    "    min_loss = loss[0]\n",
    "    while i<n:\n",
    "        if loss[i]>min_loss*(1+threshold) and np.max(loss[i-patience:i])<=min_loss*(1+threshold):\n",
    "            return i\n",
    "        i+=1\n",
    "        min_loss = min(min_loss,loss[i-patience])\n",
    "    return n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50adcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "if plot_linear:\n",
    "    from sklearn import linear_model\n",
    "    num_trial = 5\n",
    "    test_acc_array_linear = np.zeros([len(input_num_list),num_trial])\n",
    "    beta = 1e-3\n",
    "    for j in tqdm(range(num_trial)):\n",
    "        for i, input_num in enumerate(input_num_list):\n",
    "            index = np.arange(num_train)\n",
    "            training_data_np_sub = training_data_np[index[:input_num]]\n",
    "            training_labels_np_sub = training_labels_np[index[:input_num]]\n",
    "            clf = linear_model.Lasso(alpha=beta)\n",
    "            clf.fit(training_data_np_sub,training_labels_np_sub)\n",
    "            logits = clf.predict(test_data_np)\n",
    "            test_acc = accuracy(logits,test_labels_np)\n",
    "            test_acc_array_linear[i,j] = test_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e85cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num_list = [100,200,500,1000,2000,5000,10000,20000]\n",
    "if data_name == 'Amazon':\n",
    "    input_num_list = [100,200,500,1000,2000,5000,10000]\n",
    "elif data_name == 'cola':\n",
    "    input_num_list = [100,200,500,1000,2000]\n",
    "if train_num_str == '_TN_f1':\n",
    "    input_num_list = 200*np.arange(1,11)\n",
    "elif train_num_str == '_TN_f2':\n",
    "    input_num_list = 50*np.arange(4,11)\n",
    "elif train_num_str == '_TN_f3':\n",
    "    input_num_list = [5000,10000]\n",
    "time_str = ''\n",
    "mode='early_stop'\n",
    "# mode='best'\n",
    "time_str = '_early_stop'\n",
    "patience = 3\n",
    "threshold = 1e-2\n",
    "if data_name == 'Amazon':\n",
    "    threshold = 2e-2\n",
    "elif data_name == 'qqp':\n",
    "    threshold = 1e-3\n",
    "elif data_name == 'mnist':\n",
    "    threshold = 2e-1\n",
    "beta_list_lasso = [1e-1,1e-2,1e-3,1e-4]\n",
    "test_acc_array, t_array = compute_test_acc_cvx(result_dict_cvx,input_num_list,mode=mode,\n",
    "                                                patience=patience,threshold=threshold)\n",
    "test_acc_array_noncvx = compute_test_acc_noncvx(result_dict_noncvx,t_array,input_num_list)\n",
    "if plot_lasso:\n",
    "    test_acc_array_lasso = compute_test_acc_lasso(result_dict_lasso,input_num_list,beta_list_lasso)\n",
    "if plot_polish:\n",
    "    test_acc_array_polish = compute_test_acc_noncvx(result_dict_polish,result_dict_cvx,input_num_list,coef)\n",
    "# if plot_full:\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ls = 'dotted'\n",
    "scale = 1\n",
    "for j1, method in enumerate(methods):\n",
    "    target = np.max(test_acc_array[:,j1,:,:],axis=1)*100\n",
    "    t_mean = np.mean(target,axis=1)\n",
    "    t_std = np.sqrt(np.var(target,axis=1))\n",
    "    ax.errorbar(input_num_list, t_mean, yerr=scale*t_std, label='CVX {}'.format(method),linestyle=ls,marker='o',markersize=4,capsize=4)\n",
    "\n",
    "target = np.max(test_acc_array_noncvx,axis=1)\n",
    "t_mean = np.mean(target,axis=1)\n",
    "t_std = np.sqrt(np.var(target,axis=1))\n",
    "ax.errorbar(input_num_list, t_mean, yerr=scale*t_std, label='nonCVX AdamW',linestyle=ls,marker='o',markersize=4,capsize=4)\n",
    "\n",
    "if plot_linear:\n",
    "    target = test_acc_array_linear*100\n",
    "    t_mean = np.mean(target,axis=1)\n",
    "    t_std = np.sqrt(np.var(target,axis=1))\n",
    "    ax.errorbar(input_num_list, t_mean, yerr=scale*t_std, label='linear',linestyle=ls,marker='o',markersize=4,capsize=4)\n",
    "\n",
    "ax.legend()\n",
    "log=False\n",
    "log_str = ''\n",
    "if log:\n",
    "    ax.set_xscale('log')\n",
    "    log_str = '-log'\n",
    "ax.set_xlabel('Training data amount')\n",
    "ax.set_ylabel('Test accuracy')\n",
    "str_bundle = time_str+train_num_str+shuffle_str+skip_str+solver_str+eps_str+aug_str\n",
    "fig.savefig('figures/FT-input-num-{}-{}-Hidden{}{}.pdf'.format(data_name,embed,Hidden,str_bundle),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd96cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num = 2000\n",
    "\n",
    "def append_zero(np_array):\n",
    "    return np.concatenate([[0],np_array])\n",
    "\n",
    "number = 10\n",
    "cmap = plt.get_cmap('jet')\n",
    "    # colors = [cmap(i) for i in np.linspace(0, 1, number)]\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(10, 5))\n",
    "for i0 in range(2):\n",
    "    ax = axes[i0]\n",
    "    index = 0\n",
    "\n",
    "    for e, method in enumerate(methods):\n",
    "        best_beta_idx = np.argmax(test_acc_array[-1,e,:,0])\n",
    "        beta = beta_list[best_beta_idx]\n",
    "        train_acc_list = []\n",
    "        for i in range(num_trial):\n",
    "            key = '{}_{}_{}_{}'.format(input_num,method,beta,i)\n",
    "            metrics = result_dict_cvx[key]\n",
    "            if i0==0:\n",
    "                train_acc = metrics.train_accuracy\n",
    "            else:\n",
    "                train_acc = metrics.test_accuracy\n",
    "            train_acc_list.append(train_acc)\n",
    "        min_train_acc_len = np.min([len(x) for x in train_acc_list])\n",
    "        train_acc_array = np.zeros([num_trial, min_train_acc_len])\n",
    "        for i in range(num_trial):\n",
    "            train_acc_array[i,:] = train_acc_list[i][:min_train_acc_len]\n",
    "        target = train_acc_array*100\n",
    "        t_mean = np.mean(target,axis=0)\n",
    "        t_std = np.sqrt(np.var(target,axis=0))\n",
    "        cum_time = metrics.time[:min_train_acc_len]\n",
    "        ax.plot(cum_time, t_mean, label='CVX {}'.format(method))\n",
    "        ax.fill_between(cum_time, t_mean - scale*t_std, t_mean + scale*t_std, alpha=0.2)\n",
    "        index+=1\n",
    "\n",
    "    x_lim = cum_time[-1]\n",
    "\n",
    "    best_lr_idx = np.argmax(test_acc_array_noncvx[-1,:,0])\n",
    "    lr = lr_list[best_lr_idx]\n",
    "    train_acc_list = []\n",
    "    for i in range(num_trial):\n",
    "        key = '{}_{}_{}'.format(input_num,lr,i)\n",
    "        if i0==0:\n",
    "            train_acc = result_dict_noncvx[key]['train_acc']\n",
    "        else:\n",
    "            train_acc = result_dict_noncvx[key]['test_acc']\n",
    "        train_acc_list.append(train_acc)\n",
    "    min_train_acc_len = np.min([len(x) for x in train_acc_list])\n",
    "    train_acc_array = np.zeros([num_trial, min_train_acc_len])\n",
    "    for i in range(num_trial):\n",
    "        train_acc_array[i,:] = train_acc_list[i][:min_train_acc_len]\n",
    "    target = train_acc_array\n",
    "    t_mean = append_zero(np.mean(target,axis=0))\n",
    "    t_std = append_zero(np.sqrt(np.var(target,axis=0)))\n",
    "    cum_time = append_zero(result_dict_noncvx[key]['cum_time'][:min_train_acc_len])\n",
    "    ax.plot(cum_time, t_mean, label='nonCVX AdamW')\n",
    "    ax.fill_between(cum_time, t_mean - scale*t_std, t_mean + scale*t_std, alpha=0.2)\n",
    "    index+=1\n",
    "\n",
    "\n",
    "    x_lim = min(x_lim, cum_time[-1])\n",
    "    if i0==0:\n",
    "        title_str = 'Training'\n",
    "    else:\n",
    "        title_str = 'Test'\n",
    "    ax.set_title('{} Accuracy'.format(title_str))\n",
    "    ax.set_xlabel('Cumulative Time (s)')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    theta=1.2\n",
    "    x_lim = max(t_array[-1]*theta,0.5)\n",
    "    ax.set_xlim([0,x_lim])\n",
    "    if i0==1:\n",
    "        if data_name == 'ECG-signal' or data_name == 'qqp':\n",
    "            y_lims = [60,80]\n",
    "        elif data_name == 'cola':\n",
    "            y_lims = [60,80]\n",
    "        elif data_name == 'cifar10':\n",
    "            y_lims = [70,90]\n",
    "        else:\n",
    "            y_lims = [80,100]\n",
    "    else:\n",
    "        if data_name == 'ECG-signal' or data_name == 'qqp':\n",
    "            y_lims = [60,100]\n",
    "        elif data_name == 'IMDB':\n",
    "            y_lims = [70,100]\n",
    "        else:\n",
    "            y_lims = [80,100]\n",
    "    ax.set_ylim(y_lims)\n",
    "    ax.legend()\n",
    "str_bundle = time_str+train_num_str+shuffle_str+skip_str+solver_str+eps_str+aug_str+'_IN{}'.format(input_num)\n",
    "fig.savefig('figures/TR-input-num-{}-{}-Hidden{}{}.pdf'.format(data_name,embed,Hidden,str_bundle),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b04f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82648f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
